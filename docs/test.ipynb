{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\armoshar\\OneDrive - Microsoft\\Projects\\OpenAI\\semantic-router\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "current_script_path = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_script_path)\n",
    "#subfolder_path = os.path.join(parent_dir)\n",
    "\n",
    "print(parent_dir)\n",
    "# adding Folder_2 to the system path\n",
    "sys.path.insert(0, parent_dir)\n",
    " \n",
    "# importing the add and odd_even\n",
    "# function\n",
    " \n",
    "from semantic_router import Route\n",
    "from semantic_router.encoders import CohereEncoder, OpenAIEncoder, AzureOpenAIEncoder\n",
    "\n",
    "politics = Route(\n",
    "    name=\"politics\",\n",
    "    utterances=[\n",
    "        \"isn't politics the best thing ever\",\n",
    "        \"why don't you tell me about your political opinions\",\n",
    "        \"don't you just love the president\",\n",
    "        \"don't you just hate the president\",\n",
    "        \"they're going to destroy this country!\",\n",
    "        \"they will save the country!\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "encoder = AzureOpenAIEncoder(api_key=api_key, azure_endpoint=azure_endpoint, api_version=\"2023-07-01-preview\",\n",
    "                            model=\"text-embedding-ada-002\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction(start : str)->str:\n",
    "    \"\"\"just produce a direction from the starting point to the library\n",
    "    :param start: the starting address\n",
    "    :type start: str\n",
    "\n",
    "    \n",
    "    :return: the direction\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"From main street to the library: go left and right and you get there in 5 minutes\")\n",
    "\n",
    "\n",
    "def do_fuzzy_case()->str:\n",
    "    \"\"\"Handle the fuzzy case questions \n",
    "   \n",
    "    return: the text\n",
    "    \"\"\"\n",
    "    print(\"I need mroe information to help you with that\")\n",
    "\n",
    "def do_irrelevant()->str:\n",
    "    \"\"\"Handle the irrelevant questions \n",
    "   \n",
    "    return: the text\n",
    "    \"\"\"\n",
    "    print(\"I don't know how to help you with that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_router.utils.function_call import get_schema\n",
    "\n",
    "direction_schema = get_schema(get_direction)\n",
    "fuzzy_schema = get_schema(do_fuzzy_case)\n",
    "irrelevant_schema = get_schema(do_irrelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_direction',\n",
       " 'description': 'just produce a direction from the starting point to the library\\n:param start: the starting address\\n:type start: str\\n\\n\\n:return: the direction',\n",
       " 'signature': '(start) -> str',\n",
       " 'output': \"<class 'str'>\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direction_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = Route(\n",
    "    name=\"get_direction\",\n",
    "    utterances=[\n",
    "        \"How do I get to the closes park?\",\n",
    "        \"I want to go to the nearest restaurant\",\n",
    "        \"I want to go to the nearest restaurant from my location\",\n",
    "        \"I want to go to the nearest restaurant from my location to my home\",\n",
    "        \"I want to go to a library in city of Dallas\",\n",
    "        \"How do I get to the mall?\",\n",
    "        \"find me the best route to the closes Chines restaurant\",\n",
    "        \"How far is the drive from my mom's house to the nearest grocery store\",\n",
    "    ],\n",
    "    function_schema=direction_schema,\n",
    ")\n",
    "\n",
    "fuzzycase = Route(\n",
    "    name=\"do_fuzzy_case\",\n",
    "    utterances=[\n",
    "        \"I want to go to the nearest restaurant from my location to my home but I want to stop by the grocery store\",\n",
    "        \"How do I get to a different continent from my home\",\n",
    "        \"I want to go to the libary but I want to stop by the grocery store and then go to the nearest restaurant and come back\",\n",
    "        \"City of Austin to Los Angeles\",\n",
    "        \"Ski Slopes\",\n",
    "    ],\n",
    "    function_schema=fuzzy_schema,\n",
    ")\n",
    "\n",
    "irrelevant = Route(\n",
    "    name=\"do_irrelevant\",\n",
    "    utterances=[\n",
    "        \"How do I make grilled lobster\",\n",
    "        \"What is the best book for finding the driving directions\",\n",
    "        \"What is the best song\",\n",
    "        \"Can you tell me the most popular color in the world\",\n",
    "        \"Tell me a joke\",   \n",
    " ],\n",
    "    function_schema=irrelevant_schema,\n",
    ")\n",
    "\n",
    "routes = [direction, fuzzycase, irrelevant ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-16 15:24:32 INFO semantic_router.utils.logger Initializing RouteLayer\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from semantic_router.layer import RouteLayer\n",
    "from semantic_router.llms import AzureOpenAILLM\n",
    "\n",
    "\n",
    "llm = AzureOpenAILLM(openai_api_key=api_key, azure_endpoint=azure_endpoint) \n",
    "rl = RouteLayer(encoder=encoder, routes=routes, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-16 15:24:33 INFO semantic_router.utils.logger LLM  `name='gpt-35-turbo' client=<openai.lib.azure.AzureOpenAI object at 0x000002324D651630> temperature=0.01 max_tokens=200` is chosen\u001b[0m\n",
      "\u001b[32m2024-01-16 15:24:33 INFO semantic_router.utils.logger this is the llm passed to route object name='gpt-35-turbo' client=<openai.lib.azure.AzureOpenAI object at 0x000002324D651630> temperature=0.01 max_tokens=200\u001b[0m\n",
      "\u001b[32m2024-01-16 15:24:33 INFO semantic_router.utils.logger Extracting function input...\u001b[0m\n",
      "\u001b[32m2024-01-16 15:24:33 INFO semantic_router.utils.logger LLM output: {\n",
      "            \"start\": \"my home\"\n",
      "        }\u001b[0m\n",
      "\u001b[32m2024-01-16 15:24:33 INFO semantic_router.utils.logger Function inputs: {'start': 'my home'}\u001b[0m\n",
      "\u001b[32m2024-01-16 15:24:33 INFO semantic_router.utils.logger param info ['start) -> st']\u001b[0m\n",
      "\u001b[32m2024-01-16 15:24:33 INFO semantic_router.utils.logger param names ['start) -> st']\u001b[0m\n",
      "\u001b[31m2024-01-16 15:24:33 ERROR semantic_router.utils.logger Input validation error: list index out of range\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid inputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mrl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhow do I get to the nearest gas station from my home?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\armoshar\\OneDrive - Microsoft\\Projects\\OpenAI\\semantic-router\\semantic_router\\layer.py:203\u001b[0m, in \u001b[0;36mRouteLayer.__call__\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    201\u001b[0m             route\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\n\u001b[0;32m    202\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM  `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroute\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is chosen\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mroute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;66;03m# if no route passes threshold, return empty route choice\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RouteChoice()\n",
      "File \u001b[1;32mc:\\Users\\armoshar\\OneDrive - Microsoft\\Projects\\OpenAI\\semantic-router\\semantic_router\\route.py:57\u001b[0m, in \u001b[0;36mRoute.__call__\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM is required for dynamic routes. Please ensure the `llm` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute is set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m     )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# if a function schema is provided we generate the inputs\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m extracted_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_function_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_schema\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextracted inputs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextracted_inputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m func_call \u001b[38;5;241m=\u001b[39m extracted_inputs\n",
      "File \u001b[1;32mc:\\Users\\armoshar\\OneDrive - Microsoft\\Projects\\OpenAI\\semantic-router\\semantic_router\\llms\\base.py:90\u001b[0m, in \u001b[0;36mBaseLLM.extract_function_inputs\u001b[1;34m(self, query, function_schema)\u001b[0m\n\u001b[0;32m     88\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction inputs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_inputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_valid_inputs(function_inputs, function_schema):\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid inputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_inputs\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid inputs"
     ]
    }
   ],
   "source": [
    "out = rl(\"how do I get to the nearest gas station from my home?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Message(role='user', content='\\nYou are a helpful assistant designed to output JSON.\\nGiven the following function schema\\n<< {\\'name\\': \\'do_irrelevant\\', \\'description\\': \\'Handle the irrelevant questions \\\\n\\\\nreturn: the text\\', \\'signature\\': \\'() -> str\\', \\'output\\': \"<class \\'str\\'>\"} >>\\nand query\\n<< \\n        \"How do I make grilled lobster\",\\n        \"What is the best book for finding the driving directions\",\\n        \"What is the best song\",\\n        \"Can you tell me the most popular color in the world\",\\n        \"Tell me a joke\",   \\n     >>\\nextract the parameters values from the query, in a valid JSON format.\\nExample:\\nInput:\\nquery: \"How is the weather in Hawaii right now in International units?\"\\nschema:\\n{\\n    \"name\": \"get_weather\",\\n    \"description\": \"Useful to get the weather in a specific location\",\\n    \"signature\": \"(location: str, degree: str) -> str\",\\n    \"output\": \"<class \\'str\\'>\",\\n}\\n\\nResult: {\\n    \"location\": \"London\",\\n    \"degree\": \"Celsius\",\\n}\\n\\nInput:\\nquery: \\n        \"How do I make grilled lobster\",\\n        \"What is the best book for finding the driving directions\",\\n        \"What is the best song\",\\n        \"Can you tell me the most popular color in the world\",\\n        \"Tell me a joke\",   \\n    \\nschema: {\\'name\\': \\'do_irrelevant\\', \\'description\\': \\'Handle the irrelevant questions \\\\n\\\\nreturn: the text\\', \\'signature\\': \\'() -> str\\', \\'output\\': \"<class \\'str\\'>\"}\\nResult:\\n')]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m output \u001b[38;5;241m=\u001b[39m llm_input\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m---> 60\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m function_inputs \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(output)\n\u001b[0;32m     64\u001b[0m function_inputs\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "\n",
    "from pydantic import BaseModel\n",
    "class Message(BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "    def to_openai(self):\n",
    "        if self.role.lower() not in [\"user\", \"assistant\", \"system\"]:\n",
    "            raise ValueError(\"Role must be either 'user', 'assistant' or 'system'\")\n",
    "        return {\"role\": self.role, \"content\": self.content}\n",
    "\n",
    "    def to_cohere(self):\n",
    "        return {\"role\": self.role, \"message\": self.content}\n",
    "\n",
    "    def to_llamacpp(self):\n",
    "        return {\"role\": self.role, \"content\": self.content}\n",
    "import json\n",
    "import logging\n",
    "query=\"\"\"\n",
    "        \"How do I make grilled lobster\",\n",
    "        \"What is the best book for finding the driving directions\",\n",
    "        \"What is the best song\",\n",
    "        \"Can you tell me the most popular color in the world\",\n",
    "        \"Tell me a joke\",   \n",
    "    \"\"\"\n",
    "function_schema = irrelevant_schema\n",
    "logging.info(\"Extracting function input...\")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a helpful assistant designed to output JSON.\n",
    "Given the following function schema\n",
    "<< {function_schema} >>\n",
    "and query\n",
    "<< {query} >>\n",
    "extract the parameters values from the query, in a valid JSON format.\n",
    "Example:\n",
    "Input:\n",
    "query: \"How is the weather in Hawaii right now in International units?\"\n",
    "schema:\n",
    "{{\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Useful to get the weather in a specific location\",\n",
    "    \"signature\": \"(location: str, degree: str) -> str\",\n",
    "    \"output\": \"<class 'str'>\",\n",
    "}}\n",
    "\n",
    "Result: {{\n",
    "    \"location\": \"London\",\n",
    "    \"degree\": \"Celsius\",\n",
    "}}\n",
    "\n",
    "Input:\n",
    "query: {query}\n",
    "schema: {function_schema}\n",
    "Result:\n",
    "\"\"\"\n",
    "llm_input = [Message(role=\"user\", content=prompt)]\n",
    "output = llm_input\n",
    "\n",
    "print(output)\n",
    "output = output.replace(\"'\", '\"').strip().rstrip(\",\")\n",
    "\n",
    "function_inputs = json.loads(output)\n",
    "\n",
    "function_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
